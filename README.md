
# PrÃ©diction de la RUL des moteurs turbofan (NASA CMAPSS â€“ FD001)

Ce projet a pour objectif de prÃ©dire la Remaining Useful Life (RUL) de moteurs dâ€™avion turbofan Ã  partir du jeu de donnÃ©es CMAPSS de la NASA (sous-ensemble FD001), dans un contexte de maintenance prÃ©dictive.

Plusieurs approches de Machine Learning et Deep Learning sont comparÃ©es :

Random Forest (modÃ¨le tabulaire)

Autoencoder LSTM + rÃ©gression

LSTM direct pour la prÃ©diction de la RUL

1. Jeu de donnÃ©es

Le projet utilise les fichiers suivants du dataset CMAPSS (FD001) :

train_FD001.txt
Historique complet de plusieurs moteurs jusquâ€™Ã  la panne.
Chaque ligne contient :

engine_id : identifiant du moteur

cycle : numÃ©ro de cycle

os1, os2, os3 : operating settings

s1 â€¦ s21 : mesures de 21 capteurs

test_FD001.txt
Historique de nouveaux moteurs, sans RUL explicite (utilisÃ© pour le test).

RUL_FD001.txt
Fichier donnant, pour chaque moteur du test, la RUL vraie au dernier cycle observÃ©.

ğŸ‘‰ Ã€ partir de train_FD001, la RUL est reconstruite pour chaque cycle :

RUL
=
max_cycle_par_moteur
âˆ’
cycle_courant
RUL=max_cycle_par_moteurâˆ’cycle_courant
2. Approche globale

Le projet suit les Ã©tapes principales suivantes :

PrÃ©traitement & exploration

Lecture des fichiers train_FD001 et test_FD001

Suppression des capteurs constants ou quasi constants

Normalisation des features (moyenne / Ã©cart-type sur le train)

Construction des fenÃªtres temporelles (time windows)

Pour chaque moteur, les donnÃ©es sont dÃ©coupÃ©es en fenÃªtres glissantes de taille fixe (ex. 30 cycles)

Chaque Ã©chantillon = sÃ©quence de WINDOW_SIZE cycles dâ€™un moteur
Cible = RUL au dernier cycle de la fenÃªtre

ModÃ¨les entraÃ®nÃ©s

Random Forest

EntrÃ©e : features tabulaires (snapshot Ã  un cycle donnÃ©)

Ne modÃ©lise pas explicitement la dynamique temporelle

Autoencoder LSTM + rÃ©gression

Autoencoder LSTM :

EntrÃ©e : sÃ©quences de capteurs

Sortie : mÃªme sÃ©quence (reconstruction)

Le goulot (latent) sert de reprÃ©sentation compressÃ©e

RÃ©gressseur :

EntrÃ©e : vecteur latent

Sortie : RUL

Apprentissage en deux temps :
AE (non supervisÃ©) puis rÃ©gression (supervisÃ©)

LSTM direct

EntrÃ©e : fenÃªtre de WINDOW_SIZE cycles (sÃ©quence)

Sortie : RUL au dernier cycle

ModÃ¨le sÃ©quentiel de bout en bout, sans Ã©tape de compression sÃ©parÃ©e

Ã‰valuation

Pour chaque moteur du test :

On prend la prÃ©diction de RUL au dernier cycle disponible

On compare Ã  la RUL vraie de RUL_FD001.txt

MÃ©triques :

MAE (Mean Absolute Error)

RMSE (Root Mean Squared Error)

Pourcentage de moteurs prÃ©dits dans Â±5, Â±10, Â±20 cycles

Visualisations :

Nuages de points RUL vraie vs RUL prÃ©dite

Histogrammes dâ€™erreurs

Comparaison par moteur (barres True vs Pred)

3. Structure du dÃ©pÃ´t

Exemple de structure (Ã  adapter Ã  ton repo rÃ©el) :

.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train_FD001.txt
â”‚   â”œâ”€â”€ test_FD001.txt
â”‚   â””â”€â”€ RUL_FD001.txt
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploration.ipynb
â”‚   â”œâ”€â”€ 02_random_forest.ipynb
â”‚   â”œâ”€â”€ 03_autoencoder_lstm.ipynb
â”‚   â””â”€â”€ 04_direct_lstm.ipynb
â”œâ”€â”€ visualize.py          # fonctions utilitaires de visualisation (plots)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

4. Installation & exÃ©cution
4.1. CrÃ©ation de lâ€™environnement
# CrÃ©ation d'un environnement virtuel (exemple Python 3.10)
python -m venv .venv
source .venv/bin/activate    # Linux/Mac
# .venv\Scripts\activate.bat  # Windows

pip install --upgrade pip
pip install -r requirements.txt


Dans requirements.txt, on retrouve typiquement :

numpy
pandas
matplotlib
scikit-learn
tensorflow

4.2. Lancement des notebooks
jupyter notebook


Puis ouvrir les notebooks dans le dossier notebooks/ et exÃ©cuter les cellules dans lâ€™ordre.

5. RÃ©sultats principaux (rÃ©sumÃ© qualitatif)

La Random Forest fournit un premier benchmark raisonnable, mais :

les erreurs sont plus dispersÃ©es,

le modÃ¨le a tendance Ã  surestimer la RUL (biais optimiste).

Le modÃ¨le Autoencoder LSTM + rÃ©gression profite de la modÃ©lisation temporelle, mais :

la compression dans un latent space induit une certaine perte dâ€™information,

les erreurs restent plus Ã©levÃ©es et plus instables que pour le LSTM direct.

Le LSTM direct est le modÃ¨le le plus performant :

nuage de points RUL vraie vs RUL prÃ©dite plus serrÃ© autour de la diagonale,

distribution dâ€™erreurs plus centrÃ©e, avec moins de valeurs extrÃªmes,

meilleures valeurs de MAE / RMSE sur le jeu de test.

Conclusion :

La prise en compte explicite de la dimension temporelle via un LSTM de bout en bout amÃ©liore significativement la prÃ©diction de la RUL, par rapport Ã  une approche tabulaire (Random Forest) ou Ã  une architecture Autoencoder plus complexe.

6. Pistes dâ€™amÃ©lioration

Quelques idÃ©es pour aller plus loin :

Tester dâ€™autres architectures sÃ©quentielles : GRU, CNN 1D, modÃ¨les hybrides CNNâ€“LSTM.

Affiner la taille des fenÃªtres temporelles et Ã©ventuellement le clipping de la RUL.

AmÃ©liorer la sÃ©lection de capteurs (feature selection plus poussÃ©e).

Ã‰tendre lâ€™Ã©valuation aux autres sous-ensembles CMAPSS (FD002, FD003, FD004).

7. RÃ©fÃ©rences

NASA CMAPSS Turbofan Engine Degradation Simulation Data Set

LittÃ©rature sur la prÃ©diction de la RUL et la maintenance prÃ©dictive basÃ©e sur lâ€™apprentissage profond.
